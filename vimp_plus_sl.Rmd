---
title: "Super Learner + `vimp`: Investigating HIV-1 correlates of protection in HVTN 505"
author: "Brian Williamson"
date: "`r Sys.Date()`"
output:
  # bookdown::html_document2:
  bookdown::pdf_document2:
    toc: true

references:
- id: vanderlaan2007
  author:
  - family: van der Laan
    given: Mark J
  - family: Polley
    given: Eric C
  - family: Hubbard
    given: Alan E
  publisher: Statistical Applications in Genetics and Molecular Biology
  type: article-journal
  issued:
    year: 2007
  URL: 'https://doi.org/10.2202/1544-6115.1309'
- id: williamson2020a
  title: Nonparametric variable importance assessment using machine learning techniques
  author:
  - family: Williamson
    given: Brian D
  - family: Gilbert
    given: Peter B
  - family: Carone
    given: Marco
  - family: Simon
    given: Noah
  publisher: Biometrics
  type: article-journal
  issued:
   year: 2020
- id: williamson2020b
  title: A unified approach for inference on algorithm-agnostic variable importance
  author:
  - family: Williamson
    given: Brian D
  - family: Gilbert
    given: Peter B
  - family: Simon
    given: Noah
  - family: Carone
    given: Marco
  publisher: arXiv
  type: article-journal
  issued:
   year: 2020
  URL: https://arxiv.org/abs/2004.03683
- id: fong2018
  author:
  - family: Fong
    given: Youyi
  - family: Shen
    given: X
  - family: Ashley
    given: VC
  - family: Deal
    given: A
  - family: et al.
  publisher: Journal of Infectious Diseases
  type: article-journal
  issued:
    year: 2018
  URL: 'https://doi.org/10.1093/infdis/jiy008'
- id: janes2017
  author:
    - family: Janes
      given: HE
    - family: Cohen
      given: KW
    - family: Frahm
      given: N
    - family: De Rosa
      given: SC
    - family: Sanchez
      given: G
    - family: et al.
  publisher: Journal of Infectious Diseases
  type: article-journal
  issued:
    year: 2017
  URL: 'https://doi.org/10.1093/infdis/jix086'
- id: hammer2013
  author:
    - family: Hammer
      given: SM
    - family: Sobieszczyk
      given: ME
    - family: Janes
      given: HE
    - family: Karuna
      given: ST
    - family: Mulligan
      given: MJ
    - family: et al.
  publisher: New England Journal of Medicine
  type: article-journal
  issued:
    year: 2013
  URL: 'https://doi.org/10.1056/NEJMoa1310566'
- id: doksum2008
  author:
    - family: Doksum
      given: K
    - family: Tang
      given: S
    - family: Tsui
      given: KW
  publisher: Journal of the American Statistical Association
  type: article-journal
  issued:
    year: 2008
  URL: 'https://doi.org/10.1198/016214508000000878'
- id: neidich2019
  author:
    - family: Neidich
      given: SD
    - family: Fong
      given: Y
    - family: Li
      given: SS
    - family: Geraghty
      given: DE
    - family: Williamson
      given: BD
    - family: et al.
  publisher: The Journal of Clinical Investigation
  type: article-journal
  issued:
    year: 2019
  URL: 'https://doi.org/10.1172/JCI126391'
---

```{r setup, include=FALSE}
library("knitr")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), tidy = TRUE)
```

# Introduction

We still do not have a broadly efficacious vaccine against HIV-1. [HVTN 505](https://clinicaltrials.gov/ct2/show/NCT00865566) was a randomized, placebo-controlled trial designed to assess the efficacy of a candidate vaccine regimen in adults. Using data from this trial, we aim to:

1. Build an *estimated optimal surrogate*, a model that best predicts HIV-1 infection risk from immune response marker variables measured at month 7 and a few baseline variables; and
2. Identify the sets of immune response markers that best predict infection and how these sets work together.

We use the Super Learner [@vanderlaan2007] to address aim 1, and perform a variable importance analysis to address aim 2. Taken together, these aims constitute a correlates of risk (CoR) analysis using these data.

# Dataset

The month 7 immune markers are cross-classified by the following factors into interpretable sets:

1. Assay type: CD4 T Cell, CD8 T Cell, IgG, IgA, functional (antibody-dependent cellular phagocytosis [ADCP; referred to as `phago`], Fc$\gamma$ receptors [referred to as `fcrR2a` and `fcrR3a`], and neutralizing antibody [nAb] tier 1)
2. Antigen: any vaccine-matched HIV peptide pool ("Any HIV"), protein-specific vaccine-matched peptide pools ("Any VRC ENV", "Any VRC GAG", "Any VRC NEF", and "Any VRC POL"), Empty Ad5 VRC, CMV, gp120, gp140, V1V2, V3, p24, gp41, C1, C4

A few of the month 7 immune markers had missing values. Single imputation was used to fill in these values. We ignore uncertainty in the imputations in this analysis given the very small amount of missing data.

We performed some data cleaning and a dimension reduction step prior to the statistical analysis. Within each interpretable variable set:

* include quantitative variables and binary "high" vs. "low" variables, defined by above vs. below the median of vaccine recipients. The median is calculated for the cohort of vaccine recipients at risk of HIV-1 infection at month 7; thus, inverse sampling probability weights are used in the calculations.
* each BAMA variable (IgG, IgG3, IgA) is baseline subtracted. For IgG3 the variables are log fold-rise in immune response, whereas IgG and IgA are the log of the difference (month 7 - month 0) on the original scale. In addition, for each BAMA variable month 7 readouts without baseline subtraction are included.
* For ICS variables (CD4, CD8 T cell), magnitude measures are: percent of cells expressing IL2, TNFa, CD154, and/or IFNg; percent of cells expressing IL2 and/or IFNg; percent of cells expressing IL2 and/or TNFa; and percent of cells expressing each of the individual cytokines (TNFa, CD154, IFNg, IL2, IL4).  All of the magnitudes are log10 net responses, i.e., background-subtracted and then log10-transformed.  Polyfunctionality as measured by the COMPASS polyfunctionality score (proportion of antigen-specific cell subsets detected, weighted by their degree of functionality, where antigen-specific cell subsets are those with a statistically-significant difference in the percent of cytokine-expressing cells in unstimulated vs. stimulated samples). The following cytokines are considered in calculating the polyfunctionality score: TNFa, CD154, IFNg, IL2, IL4, and Granzyme B; however cells expressing Granzyme B only are not counted as "functional".  Note functionality scores are not included because they are highly correlated and mostly redundant conceptually with polyfunctionality scores.  Both magnitude and polyfunctional score variables are included for study, as the correlations are not uniformly high; they range from ~0.5--0.8 across antigens and T cell subsets and may capture different aspects of T cell response.
* For ICS responses to vaccine-mismatched antigens (Empty Ad5 VRC and CMV antigens), measure responses using the percent of cells expressing IL2, TNFa, CD154, and/or IFNg.
* For variables with a positive response call (IgG, IgG3, IgA, R2a, R3a, phago, Tier 1 nAb) require $>$ 20% vaccine group positive response.  For all variables, require a significantly greater response in the vaccine group than the placebo group to include in the analysis (Wilcoxon rank sum test 2-sided p $<$ 0.01).  Note that no Tier 1 nAb variables are included because none met the $>$ 20% vaccine group response criterion.
* For all variables in an interpretable variable set (defined by assay and antigen) that are for vaccine-mismatched antigens, aggregate the variables into two scores to be kept for CoR analysis: PC1 and the maximal diversity weighted score (MDWS).

The data are included in the R package HVTN505. The data are available at the [Statistical Center for HIV/AIDS Research and Prevention](https://atlas.scharp.org/cpas/project/HVTN%20Public%20Data/HVTN%20505/begin.view) website, in the `correlates` subfolder. Install the package from `HVTN505_2019-4-25.tar.gz` (you may only have access to a later date) using the following code:

```{r install-hvtn505}
# only run this line if the package isn't already installed; edit the file path
# to point to the directory where the .tar.gz file is located and make sure you have
# the correct name
# devtools::install_local("HVTN505_2019-4-25.tar.gz")
```

The object `dat.505` contains 189 rows, clinical covariates, and both continuous and dichotomized immune response biomarkers. The object `var.505` contains metadata on the individual immune response biomarkers. The object `score.505` contains metadata on the summary immune response biomarkers.

# Correlates of Risk Analysis

All models adjust for the same baseline exposure covariates adjusted for by @janes2017, except race (white, black, Hispanic) is excluded to help avoid sparsity issues: age (years old at enrollment), BMI at enrollment (quantitative value in kg/m$^2$), and baseline behavioral risk (a weighted average of two binary risk factors identified by @hammer2013). All analyses use the same empirical inverse probability sampling weights used by @janes2017 and @fong2018.  These participant weights are included in the data file (`wt` column in `dat.505` in the `HVTN505` R package).

## Candidate Variable Sets

We consider 11 candidate variable sets in this analysis, defined by assay combination:

1. All markers;
2. IgG + IgA;
3. IgG3;
4. T cells (CD4 and CD8);
5. Functional antibodies (Fx Ab);
6. IgG + IgA and IgG3;
7. IgG + IgA and T cells;
8. IgG + IgA and IgG3 and T cells;
9. IgG + IgA and IgG3 and Fx Ab;
10. T cells and Fx Ab; and
11. No markers.

In all analyses, as we mentioned above, we adjust for three baseline variables: age, BMI, and behavioral risk.

## Inverse Probability Weights

All of the following analyses rely on vaccine recipients who were at risk of HIV-1 infection at Month 7. This is a case-control cohort within the full HVTN 505 analysis dataset. Thus, all of our analyses must account for this sampling. The HVTN 505 correlates dataset `dat.505` contains the weights for the vaccine recipients, which is useful for running the regressions of outcome on various sets of covariates. However, to fully account for the case-control sampling, we need the weights for all vaccine recipients along with an indicator of which vaccine recipients are in the case-control cohort. The following code uses the full HVTN 505 data to obtain weights for each trial participant, which we will use in the subsequent sections.

```{r get_all_weights}
library("dplyr")
library("tidyr")
library("tibble")
library("readr")
# ------------------------------------------------------
# Read in the full dataset and make sure that
# strata are computed across ALL participants
# ------------------------------------------------------
# these data come from the SCHARP ATLAS page for 505,
# https://atlas.scharp.org/cpas/project/HVTN%20Public%20Data/HVTN%20505/begin.view?
# (select primary505_for_sharing.csv within the Fong et al. (2018, JID) folder)
# I've saved this in a data/ subfolder, but change the path to where you've saved it
full_data <- readr::read_csv("data/primary505_for_sharing.csv")
full_data_with_strata <- full_data %>%
  mutate(hg_strata = ifelse(is.na(hg_strata),
                            paste0(
                              ifelse(trt == 0, "Plac/", "Vacc/"),
                              ifelse(racecc == "White", "White", "Blk_Hisp"),
                              ifelse(trt == 1 & is.na(BMI), "/Missing", ""),
                              ifelse(trt == 1 & BMI < 25 & !is.na(BMI), "/[18.4, 25)", ""),
                              ifelse(trt == 1 & 25 <= BMI & BMI < 29.8 & !is.na(BMI), "/[25, 29.8)", ""),
                              ifelse(trt == 1 & 29.8 <= BMI & !is.na(BMI), "/[29.8, 40)", "")
                            ),
                            hg_strata)) %>%
  filter(!is.na(BMI))

# read in table to match pub_id from this dataset with the
# ID in the HVTN505 R package
pub_id_converter <- readr::read_csv("data/rx_v2.csv") %>%
  select(Ptid, pub_id) %>%
  rename(hvtn505_id = Ptid) %>%
  mutate(hvtn505_id = gsub("-", "", hvtn505_id))

# update pub id
full_data_with_matched_ids <- full_data_with_strata %>%
  left_join(pub_id_converter, by = "pub_id")
# ------------------------------------------------------
# Compute inverse probability weights
# ------------------------------------------------------
# compute strata
full_data_with_stratuminds <- full_data_with_matched_ids %>%
  mutate(
    stratuminds = case_when(
      hg_strata == "Plac/Blk_Hisp" ~ 1,
      hg_strata == "Plac/White" ~ 2,
      hg_strata == "Vacc/Blk_Hisp/[18.4, 25)" ~ 3,
      hg_strata == "Vacc/Blk_Hisp/[25, 29.8)" ~ 4,
      hg_strata == "Vacc/Blk_Hisp/[29.8, 40)" ~ 5,
      hg_strata == "Vacc/White/[18.4, 25)" ~ 6,
      hg_strata == "Vacc/White/[25, 29.8)" ~ 7,
      hg_strata == "Vacc/White/[29.8, 40)" ~ 8
    ),
    stratuminds_vaccs = stratuminds - 2
  )
cc_data <- full_data_with_stratuminds %>%
  filter(casecontrol == 1)
# numbers of cases and controls in each stratum
n0 <- full_data_with_stratuminds %>%
  filter(cc_cohort == 1, HIVwk28preunbl == 0) %>%
  group_by(cc_strata) %>%
  summarize(n0 = n(), .groups = "drop")
n1 <- full_data_with_stratuminds %>%
  filter(cc_cohort == 1, HIVwk28preunbl == 1) %>%
  group_by(cc_strata) %>%
  summarize(n1 = n(), .groups = "drop")
# compute the weights
weights <- cbind(n0$n0, n1$n1) / table(cc_data$stratuminds, cc_data$HIVwk28preunbl)
full_data_with_weights <- full_data_with_stratuminds %>%
  mutate(weight = ifelse(HIVwk28preunbl == 1,
                         1,
                         weights[, 1][full_data_with_stratuminds$stratuminds]))

# final tibble
Z_plus_weights <- full_data_with_weights %>%
  select(hvtn505_id, trt, HIVpreunbl, age, BMI, bhvrisk, weight) %>%
  rename(ptid = hvtn505_id, Y = HIVpreunbl) %>%
  mutate(ptid = as.numeric(ptid)) %>%
  filter(!is.na(Y), !is.na(age), !is.na(BMI), !is.na(bhvrisk))
```

## Super Learning Analysis

We use the implementation of the Super Learner provided in the `SuperLearner` R package. In a Super Learning task, cross-validation is used to determine the optimal convex combination of a set of candidate learners chosen to minimize a cross-validated risk. This process results in an estimated risk for each of the candidate learners, along with an estimated risk for the traditional cross-validated selector and the optimal convex combination of the individual algorithms. This convex combination is called the Super Learner.

Specifying the set of candidate learners involves two steps: (1) specifying variable screens that reduce the number of variables passed to each algorithm, and (2) specifying a set of algorithms. The screens and algorithms are then combined, and each unique combination of screen and algorithm is applied to the regression problem.

Since we have only 25 events, we constructed aggressive variable screens that allowed a maximum of four marker variables into each candidate learner. In each case, the screen also forced age, BMI, and baseline behavioral risk to be adjusted for in the algorithm. The specific screens used are:

* dynamic range: exclude variables with 20th percentile equal to the 80th percentile
* dynamic range score: exclude all variables with standard deviation in the vaccinees divided by standard deviation in placebo recipients in the lower half of all participants
* lasso with fixed p-value threshold: first run a lasso (adjusting for age, BMI, and behavioral risk); then for each variable with nonzero lasso coefficient, run a logistic regression (adjusting for age, BMI, and behavioral risk) and exclude all variables for which the resulting p-value is above a threshold. We considered thresholds 0.01, 0.05, and 0.1
* high correlation: exclude any pair of variables that has Spearman correlation greater than 0.9.

The specific Super Learner algorithms we considered were:

* generalized linear models;
* generalized linear models with pairwise interactions;
* forward stepwise regression with pairwise interactions;
* boosted decision stumps: boosted trees with maximum depth of one node; and
* the `earth` algorithm of @doksum2008.

In each case, we used a logit link function to relate the predictor variables to the risk of HIV-1 infection.

These screens and algorithms are implemented in R using the following code:

```{r define-screens-and-algs, code = readLines("code/sl_screens.R")}
```

We used two layers of nested cross-validation in this analysis. To obtain cross-validated estimates of risk, we used an outer layer of five-fold cross-validation stratified so that an equal proportion of events fell within each fold. To obtain estimates of the regression functions within each outer fold, we used an inner layer of leave-one-out cross-validation. We used the cross-validated negative log likelihood to determine our optimal convex combination of learners. Since the results may depend on the random number seed used to generate the folds for the outer layer of five-fold cross-validation, we used ten random seeds, and for each seed ran the full nested cross-validation procedure.

Our resulting proposed estimator for objective (1) above is the cross-validated Super Learner averaged over the ten random seeds, where each prediction is based on a leave-one-out cross-validated Super Learner when the particular observation was in the outer validation fold.

We next define some useful functions that we will use in subsequent analyses:

```{r utils, code = readLines("code/utils.R")}
```

The following code runs the full Super Learner with a reduced library of candidate learners. This is for illustration only --- we recommend using a large library of candidate learners, as we did in the original analysis. Please note, however, that the following code chunk may take several minutes to run. If the code chunk does not run, a useful first debugging step is to make sure that you have installed all of the required packages.

```{r run-full-sl-with-small-lib, eval = FALSE}
# load required libraries and functions
library("methods")
library("SuperLearner")
library("e1071")
library("glmnet")
library("xgboost")
library("earth")
library("dplyr")
# only run this if something has changed
# devtools::install_local("HVTN505_2019-4-25.tar.gz")
library("HVTN505")
# only run this if something has changed
# devtools::install_github("bdwilliamson/vimp", upgrade = "never")
library("vimp")
library("kyotil")
library("argparse")

num_cores <- parallel::detectCores()
print(num_cores)
# read in screens/algos and utility functions (shown above)
source(paste0("code/sl_screens.R"))
source(paste0("code/utils.R"))

# ---------------------------------------------------------------------------------
# pre-process the data
# ---------------------------------------------------------------------------------
# read in the full dataset
data("dat.505", package = "HVTN505")
# read in the super learner variables
# even if there is a warning message, it still exists
suppressWarnings(data("var.super", package = "HVTN505"))
# note that "var.super" contains individual vars for vaccine-matched antigens,
# and for vaccine-mismatched antigens, has either individual var (if only one)
# or PC1 and/or MDW (only PC1 if cor(PC1, MDW) > 0.9)

# scale vaccine recipients to have mean 0, sd 1 for all vars
for (a in var.super$varname) {
  dat.505[[a]] <- scale(dat.505[[a]], center = mean(dat.505[[a]][dat.505$trt == 1]),
                        scale = sd(dat.505[[a]][dat.505$trt == 1]))
  dat.505[[a%.%"_bin"]] <- scale(dat.505[[a%.%"_bin"]],
                                 center = mean(dat.505[[a%.%"_bin"]][dat.505$trt == 1]),
                                 scale = sd(dat.505[[a%.%"_bin"]][dat.505$trt == 1]))
}
for (a in c("age", "BMI", "bhvrisk")) {
  dat.505[[a]] <- scale(dat.505[[a]], center = mean(dat.505[[a]][dat.505$trt == 1]),
                        scale = sd(dat.505[[a]][dat.505$trt == 1]))
}

# set up X, Y for super learning
X_markers <- dat.505 %>%
  select(var.super$varname, paste0(var.super$varname, "_bin"))
X_exposure <- dat.505 %>%
  select(age, BMI, bhvrisk)
X <- data.frame(trt = dat.505$trt, X_exposure, X_markers)
X_full_none <- data.frame(trt = dat.505$trt, X_exposure)
weights <- dat.505$wt
Y <- dat.505$case
vaccinees <- cbind.data.frame(Y, weights, X) %>%
  filter(trt == 1) %>%
  select(-trt)
X_none <- cbind.data.frame(Y, weights, X_full_none) %>%
  filter(trt == 1) %>%
  select(-trt, -Y, -weights)
Y_vaccine <- vaccinees$Y
weights_vaccine <- vaccinees$weights
X_vaccine <- vaccinees %>%
  select(-Y, -weights)

# match the rows in vaccinees to get Z, C
all_cc_vaccine <- Z_plus_weights %>%
  filter(ptid %in% vaccinees$ptid, trt == 1)
# pull out the participants who are NOT in the cc cohort and received the vaccine
all_non_cc_vaccine <- Z_plus_weights %>%
  filter(!(ptid %in% vaccinees$ptid), trt == 1)
# put them back together
phase_1_data_vaccine <- dplyr::bind_rows(all_cc_vaccine, all_non_cc_vaccine) %>%
  select(-trt)
Z_vaccine <- phase_1_data_vaccine %>%
  select(-ptid, -weight)
all_ipw_weights_vaccine <- phase_1_data_vaccine %>%
  pull(weight)
C <- (phase_1_data_vaccine$ptid %in% vaccinees$ptid)

V_outer <- 5
V_inner <- length(Y_vaccine) - 1

# ---------------------------------------------------------------------------------
# run super learner, with leave-one-out cross-validation and all screens
# do 10 random starts, average over these
# use assay groups as screens
# ---------------------------------------------------------------------------------
# ensure reproducibility
set.seed(4747)
seeds <- round(runif(10, 1000, 10000)) # average over 10 random starts
fits <- parallel::mclapply(seeds, FUN = run_cv_sl_once, Y = Y_vaccine,
                           X_mat = X_vaccine, family = "binomial",
                           Z = Z_vaccine, C = C, z_lib = "SL.glm",
                           obsWeights = weights_vaccine,
                           scale = "logit",
                           sl_lib = SL_library[1],
                           method = "method.CC_nloglik",
                           cvControl = list(V = V_outer, stratifyCV = TRUE),
                           innerCvControl = list(list(V = V_inner)),
                           vimp = FALSE,
                           mc.cores = num_cores
)
sl_fits_varset_11_all <- fits
# do the same thing for confounders only
fits <- parallel::mclapply(seeds, FUN = run_cv_sl_once, Y = Y_vaccine,
                           X_mat = X_none, family = "binomial",
                           Z = Z_vaccine, C = C, z_lib = "SL.glm",
                           obsWeights = weights_vaccine,
                           scale = "logit",
                           sl_lib = methods[1],
                           method = "method.CC_nloglik",
                           cvControl = list(V = V_outer, stratifyCV = TRUE),
                           innerCvControl = list(list(V = V_inner)),
                           vimp = FALSE,
                           mc.cores = num_cores
)
sl_fits_varset_1_baseline_exposure <- fits
```

The code to reproduce the results of the original analysis is provided in the Appendix, and was designed to run on a high-performance cluster (HPC) computer (it takes multiple hours to run).

## Variable Importance

We use the `vimp` package to compute variable importance estimates and confidence intervals. In all cases, we consider variable importance as a summary of the true data-generating distribution. Since our outcome is binary, we estimate variable importance using the population difference in area under the receiver operating characteristic curve (AUC) [@williamson2020b]. We interpret the AUC-based importance as the difference in our ability to discriminate between cases and controls based on using a group of covariates. Load the `vimp` package using the following code:

```{r load-vimp}
# only run the next line if you haven't already installed 'vimp' version 2.1.4 or later
# devtools::install_github("bdwilliamson/vimp", upgrade = "never")
library("vimp")
```

We next ran multiple Super Learners with reduced sets of covariates. Again, we originally ran this code on an HPC computer, and recommend that any final analyses use the full library of candidate learners. However, in the code below, we use a smaller library for illustration. Please note that this code chunk may take a couple of minutes to run.

```{r run-assays-with-small-lib, eval = FALSE}
# only include the following variable sets:
assays <- unique(var.super$assay)
antigens <- unique(var.super$antigen)
# 1. None (baseline variables only)
var_set_none <- rep(FALSE, ncol(X_markers))
# 2. IgG + IgA (all antigens)
var_set_igg_iga <- get_nms_group_all_antigens(X_markers, assays = c("IgG", "IgA"),
                                              assays_to_exclude = "IgG3")
# 3. IgG3
var_set_igg3 <- get_nms_group_all_antigens(X_markers, assays = "IgG3")
# 4. T cells (all antigens)
var_set_tcells <- get_nms_group_all_antigens(X_markers, assays = c("CD4", "CD8"))
# 5. Fx Ab (all antigens)
var_set_fxab <- get_nms_group_all_antigens(X_markers, assays = c("phago", "R2a", "R3a"))
# 6. 1+2+3
var_set_igg_iga_igg3 <- get_nms_group_all_antigens(X_markers, assays = c("IgG", "IgA", "IgG3"))
# 7. 1+2+4
var_set_igg_iga_tcells <- get_nms_group_all_antigens(X_markers,
                                                     assays = c("IgG", "IgA", "CD4", "CD8"),
                                                     assays_to_exclude = "IgG3")
# 8. 1+2+3+4
var_set_igg_iga_igg3_tcells <- get_nms_group_all_antigens(X_markers,
                                                          assays = c("IgG", "IgA", "IgG3", "CD4", "CD8"))
# 9. 1+2+3+5
var_set_igg_iga_igg3_fxab <- get_nms_group_all_antigens(X_markers,
                                                        assays = c("IgG", "IgA", "IgG3", "phago", "R2a", "R3a"))
# 10. 1+4+5
var_set_tcells_fxab <- get_nms_group_all_antigens(X_markers,
                                                  assays = c("CD4", "CD8", "phago", "R2a", "R3a"))
# 11. All
var_set_all <- rep(TRUE, ncol(X_markers))
# 12--14: extra runs to get variable importance
var_set_igg3_fxab <- get_nms_group_all_antigens(X_markers,
                                                assays = c("IgG3", "phago", "R2a", "R3a"))
var_set_igg_iga_tcells_fxab <- get_nms_group_all_antigens(X_markers,
                                                          assays = c("IgG", "IgA", "CD4", "CD8", "phago", "R2a", "R3a"),
                                                          assays_to_exclude = "IgG3")
var_set_igg3_tcells_fxab <- get_nms_group_all_antigens(X_markers,
                                                       assays = c("IgG3", "CD4", "CD8", "phago", "R2a", "R3a"))

var_set_names <- c("1_baseline_exposure", "2_igg_iga", "3_igg3","4_tcells", "5_fxab",
                   "6_igg_iga_igg3", "7_igg_iga_tcells", "8_igg_iga_igg3_tcells",
                   "9_igg_iga_igg3_fxab", "10_tcells_fxab",
                   "11_all",
                   "12_igg3_fxab", "13_igg_iga_tcells_fxab", "14_igg3_tcells_fxab")

# set up a matrix of all
var_set_matrix <- rbind(var_set_none, var_set_igg_iga, var_set_igg3,
                        var_set_tcells, var_set_fxab, var_set_igg_iga_igg3,
                        var_set_igg_iga_tcells, var_set_igg_iga_igg3_tcells,
                        var_set_igg_iga_igg3_fxab, var_set_tcells_fxab,
                        var_set_all, var_set_igg3_fxab,
                        var_set_igg_iga_tcells_fxab, var_set_igg3_tcells_fxab)
for (i in (1:14)[-11]) {
  job_id <- i
  this_var_set <- var_set_matrix[job_id, ]
  cat("\n Running ", var_set_names[job_id], "\n")

  X_markers_varset <- X_markers %>%
    select(names(X_markers)[this_var_set])

  X_exposure <- dat.505 %>%
    select(age, BMI, bhvrisk)
  X <- data.frame(trt = dat.505$trt, X_exposure, X_markers_varset)
  weights <- dat.505$wt
  Y <- dat.505$case
  vaccinees <- cbind.data.frame(Y, weights, X) %>%
    filter(trt == 1) %>%
    select(-trt)
  Y_vaccine <- vaccinees$Y
  weights_vaccine <- vaccinees$weights
  X_vaccine <- vaccinees %>%
    select(-Y, -weights)
  # match the rows in vaccinees to get Z, C
  all_cc_vaccine <- Z_plus_weights %>%
    filter(ptid %in% vaccinees$ptid, trt == 1)
  # pull out the participants who are NOT in the cc cohort and received the vaccine
  all_non_cc_vaccine <- Z_plus_weights %>%
    filter(!(ptid %in% vaccinees$ptid), trt == 1)
  # put them back together
  phase_1_data_vaccine <- dplyr::bind_rows(all_cc_vaccine, all_non_cc_vaccine) %>%
    select(-trt)
  Z_vaccine <- phase_1_data_vaccine %>%
    select(-ptid, -weight)
  all_ipw_weights_vaccine <- phase_1_data_vaccine %>%
    pull(weight)
  C <- (phase_1_data_vaccine$ptid %in% vaccinees$ptid)

  V_outer <- 5
  V_inner <- length(Y_vaccine) - 1

  # get the SL library
  # if var_set_none, then don't need screens; otherwise do
  if (job_id == 1) {
    sl_lib <- methods[1]
  } else {
    sl_lib <- SL_library[1]
  }
  # ---------------------------------------------------------------------------------
  # run super learner, with leave-one-out cross-validation and all screens
  # do 10 random starts, average over these
  # ---------------------------------------------------------------------------------
  # ensure reproducibility
  set.seed(4747)
  seeds <- round(runif(10, 1000, 10000)) # average over 10 random starts
  fits <- parallel::mclapply(seeds, FUN = run_cv_sl_once, Y = Y_vaccine,
                             X_mat = X_vaccine,
                             family = "binomial",
                             C = C, Z = Z_vaccine, z_lib = "SL.glm",
                             obsWeights = weights_vaccine,
                             scale = "logit",
                             sl_lib = sl_lib,
                             method = "method.CC_nloglik",
                             cvControl = list(V = V_outer, stratifyCV = TRUE),
                             innerCvControl = list(list(V = V_inner)),
                             vimp = FALSE,
                             mc.cores = num_cores
  )
  # name the object so that we can refer to it later
  eval(parse(text = paste0("sl_fits_varset_", var_set_names[job_id], " <- fits")))
}
```

# Results

## Compiling Results and Creating Plots

The following code compiles results and creates plots, and must be run after all Super Learner fits have been obtained.

```{r compile-results-small-lib, eval = FALSE}
# results from full SL analysis
# includes CV-AUC plots

# --------------------------------------------------------------------------------------------------------------------------------------
# set up directories, load required packages
# --------------------------------------------------------------------------------------------------------------------------------------
library("SuperLearner")
library("cvAUC")
library("tidyr")
library("dplyr")
library("ggplot2")
library("cowplot")
theme_set(theme_cowplot())
library("vimp")
library("kyotil")
method <- "method.CC_nloglik" # since SuperLearner relies on this to be in GlobalEnv
library("xgboost")
# The palette with black:
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# load in the data to get weights
# read in the full dataset
data("dat.505", package = "HVTN505")
# read in the super learner variables
suppressWarnings(data("var.super", package = "HVTN505"))

weights_vaccine <- dat.505$wt[dat.505$trt == 1]
# --------------------------------------------------------------------------------------------------------------------------------------
# load results objects:
# --------------------------------------------------------------------------------------------------------------------------------------
# each is a length 10 list (one for each random start)
var_set_names <- c("1_baseline_exposure", "2_igg_iga", "3_igg3","4_tcells", "5_fxab",
                   "6_igg_iga_igg3", "7_igg_iga_tcells", "8_igg_iga_igg3_tcells",
                   "9_igg_iga_igg3_fxab", "10_tcells_fxab",
                   "11_all")
# objects are created above

# average the AUCs over the 10 folds, for each
var_set_labels <- c("No markers", "IgG + IgA", "IgG3", "T Cells", "Fx Ab", "IgG + IgA + IgG3",
                    "IgG + IgA + T Cells", "IgG + IgA + IgG3 + T Cells",
                    "IgG + IgA + IgG3 + Fx Ab", "T Cells + Fx Ab", "All markers")
for (i in 1:(length(var_set_names))) {
  eval(parse(text = paste0("all_aucs_i <- as_tibble(rbindlist(lapply(sl_fits_varset_",
                             var_set_names[i],
                             ", function(x) x$aucs)))")))
    all_aucs_i <- all_aucs_i %>%
      filter(!is.na(Learner))
    this_name <- paste(unlist(strsplit(var_set_names[i], "_", fixed = TRUE))[-1], collapse = "_")
    eval(parse(text = paste0("avg_aucs_", var_set_names[i]," <- all_aucs_i %>%
    group_by(Learner, Screen) %>%
    summarize(AUC = mean(AUC), ci_ll = mean(ci_ll), ci_ul = mean(ci_ul), .groups = 'drop') %>%
    mutate(assay = this_name, varset_label = var_set_labels[i])")))
}

# combine into a full tibble; add a column to each that is the assay
avg_aucs <- bind_rows(avg_aucs_1_baseline_exposure, avg_aucs_2_igg_iga, avg_aucs_3_igg3,
                      avg_aucs_4_tcells, avg_aucs_5_fxab, avg_aucs_6_igg_iga_igg3,
                      avg_aucs_7_igg_iga_tcells, avg_aucs_8_igg_iga_igg3_tcells,
                      avg_aucs_9_igg_iga_igg3_fxab, avg_aucs_10_tcells_fxab,
                      avg_aucs_11_all)
```

```{r test}
avg_aucs <- tibble(Learner = NA, varset_label = NA, AUC = NA, ci_ll = NA, ci_ul = NA)
vimp_tibble <- tibble(assay_grp = NA, est = NA, cil = NA, ciu = NA)
```
The following code chunk creates a function that makes plots:
```{r plot-assays, code = readLines("code/plot_assays.R")}
```

## Super Learning Analysis

We ran the Super Learner algorithm for each of the 11 variable sets defined in Section 1 using the procedure defined in Section 2. We present the cross-validated AUC for the overall Super Learner from each of the variable sets. These are provided in Figure \@ref(fig:sl-forest-plot-auc). In the figure, the error bars are colored by immunoassay set: antibody (Ab) variables (black), no markers (yellow), T cell variables (green), and T cell and Ab variables (blue).

In Figure \@ref(fig:sl-forest-plot-auc), we see improved performance of the Super Learner when including marker variables compared to baseline risk variables only. Indeed, the Super Learner using only baseline variables and no markers has a cross-validated AUC of `r round((avg_aucs %>% filter(Learner == "SL", varset_label == "No markers"))$AUC, 3)`. Other variable sets have a smaller estimated cross-validated AUC, but this is likely due to the small candidate library that we used for this analysis. Our proposed estimator of HIV-1 infection risk among vaccinees, the cross-validated Super Learner, has an estimated AUC of `r round((avg_aucs %>% filter(Learner == "SL", varset_label == "All markers"))$AUC, 3)` based on all markers, with a 95\% confidence interval of `r paste0("[", round((avg_aucs %>% filter(Learner == "SL", varset_label == "All markers"))$ci_ll, 3), ", ", round((avg_aucs %>% filter(Learner == "SL", varset_label == "All markers"))$ci_ul, 3), "]")`. This is an improvement over the Super Learner based on only the baseline risk variables, with an estimated AUC of `r round((avg_aucs %>% filter(Learner == "SL", varset_label == "No markers"))$AUC, 3)` `r paste0("[", round((avg_aucs %>% filter(Learner == "SL", varset_label == "No markers"))$ci_ll, 3), ", ", round((avg_aucs %>% filter(Learner == "SL", varset_label == "No markers"))$ci_ul, 3), "]")`. These results must be interpreted with the large caveat that we have used a restricted set of learners in our Super Learner library to reduce computation time. A fuller set of learners is recommended for any publication-ready analysis (indeed, when we used the full library of learners in the full published analysis, the Super Learner based on all markers had a much improved AUC over the Super Learner with baseline risk variables only).

```{r sl-forest-plot-auc, fig.cap = "Forest plot of cross-validated AUC for the Super Learner and the top individual learner for each assay combination.", fig.width = 20, fig.height = 8, eval = FALSE}
# The palette with black:
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# load in code to plot CV performance (described above)
source("code/plot_assays.R")
# -----------------------------------------------------------------------------------
# FIGURE 1: forest plot of CV-AUC for the top learner
#           and SL for each assay combination
# -----------------------------------------------------------------------------------
title_font_size <- 18
main_font_size <- 5
fig_width <- fig_height <- 2590
y_title <- 0.96
auc_forest_plot_init <- plot_assays(avgs = avg_aucs, type = "auc",
                               main_font_size_forest = main_font_size * 3,
                               main_font_size_lab = main_font_size,
                               sl_only = FALSE, immunoassay = FALSE,
                               point_size = 1.5)
sl_plus_top_learner_auc_plot <- plot_grid(auc_forest_plot_init$top_learner_nms_plot,
                                          auc_forest_plot_init$top_learner_plot, nrow = 1, align = "h") +
  draw_label("Assay combination", size = title_font_size, x = 0.075, y = y_title) +
  draw_label("Algorithm", size = title_font_size, x = 0.175, y = y_title) +
  draw_label("Screen", size = title_font_size, x = 0.25, y = y_title) +
  draw_label("CV-AUC [95% CI]", size = title_font_size, x = 0.43, y = y_title)

# add on immunoassay set
avg_aucs <- avg_aucs %>%
  mutate(immunoassay_set = get_immunoassay_set(varset_label))

title_font_size <- 26
main_font_size_forest <- 31
main_font_size_lab <- 9.3
fig_width <- fig_height <- 2590
y_title <- 0.945
point_size <- 2
auc_forest_plot_plus_assay <- plot_assays(avgs = avg_aucs, type = "auc",
                               main_font_size_forest = main_font_size_forest,
                               main_font_size_lab = main_font_size_lab,
                               sl_only = TRUE, immunoassay = TRUE,
                               colors = cbbPalette,
                               point_size = point_size,
                               x_lim = c(0.4, 1.2),
                               lgnd_pos = c(0.6, 0.2))
auc_immunoassay_plot <- plot_grid(auc_forest_plot_plus_assay$top_learner_nms_plot,
                                            auc_forest_plot_plus_assay$top_learner_plot,
                                            nrow = 1, align = "h") +
  draw_label("Month 7", size = title_font_size, x = 0.07, y = y_title + 0.04,
             fontface = "bold") +
  draw_label("Marker Set", size = title_font_size, x = 0.08, y = y_title,
             fontface = "bold") +
  draw_label("CV-AUC", size = title_font_size, x = 0.35, y = y_title + 0.04,
             fontface = "bold") +
  draw_label("[95% CI]", size = title_font_size, x = 0.35, y = y_title,
             fontface = "bold")
auc_immunoassay_plot
```

## Variable Importance Analysis

We estimated the variable importance for 10 groups: all marker variables, IgG + IgA, IgG3, T cells, functional antibodies, IgG + IgA and IgG3, IgG + IgA and T cells, IgG + IgA and IgG3 and T cells, IgG + IgA and IgG3 and functional antibodies, and T cells and functional antibodies. In each case, we used the cross-validated Super Learner predictions from the analysis based on using the appropriate set of marker variables and baseline risk variables as our estimate of the full regression function; we then used the cross-validated Super Learner based on the baseline risk variables only to define the reduced regression function. This defines variable importance as the improvement in prediction performance from including a group of marker variables relative to including baseline variables only. The following code compiles the variable importance results for easy plotting:

```{r compile-vimp-results, eval = FALSE}
# ---------------------------------------------------------------------------------
# Variable importance plot for the different assay combinations:
# All markers yields the full regression fit
# Variable set 1 gives reduced for importance of all markers (group 8)
# Variable set 2 gives reduced for importance of Fx Ab + Tcells (group 7)
# Variable set 3 gives reduced for importance of IgG + IgA + Fx Ab (group 6)
# Variable set 4 gives reduced for importance of IgG + IgA + Tcells (group 5)
# Variable set 5 gives reduced for importance of Fx Ab (group 4)
# Variable set 6 gives reduced for importance of T cells (group 3)
# Variable set 7 gives reduced for importance of IgG + IgA (group 2)
# ---------------------------------------------------------------------------------
# load the data
# read in the full dataset
data("dat.505", package = "HVTN505")
# read in the super learner variables
suppressWarnings(data("var.super", package = "HVTN505"))
# note that "var.super" contains individual vars for vaccine-matched antigens,
# and for vaccine-mismatched antigens, has either individual var (if only one)
# or PC1 and/or MDW (only PC1 if cor(PC1, MDW) > 0.9)

# scale vaccine recipients to have mean 0, sd 1 for all vars
for (a in var.super$varname) {
  dat.505[[a]] <- scale(dat.505[[a]], center = mean(dat.505[[a]][dat.505$trt == 1]),
                        scale = sd(dat.505[[a]][dat.505$trt == 1]))
  dat.505[[a%.%"_bin"]] <- scale(dat.505[[a%.%"_bin"]],
                                 center = mean(dat.505[[a%.%"_bin"]][dat.505$trt == 1]),
                                 scale = sd(dat.505[[a%.%"_bin"]][dat.505$trt == 1]))
}
for (a in c("age", "BMI", "bhvrisk")) {
  dat.505[[a]] <- scale(dat.505[[a]], center = mean(dat.505[[a]][dat.505$trt == 1]),
                        scale = sd(dat.505[[a]][dat.505$trt == 1]))
}

# set up X, Y for super learning
X_markers <- dat.505 %>%
  select(var.super$varname, paste0(var.super$varname, "_bin"))
X_exposure <- dat.505 %>%
  select(age, BMI, bhvrisk)
X <- data.frame(trt = dat.505$trt, X_exposure, X_markers)
weights <- dat.505$wt
Y <- dat.505$case
vaccinees <- cbind.data.frame(Y, weights, X) %>%
  filter(trt == 1) %>%
  select(-trt)
Y_vaccine <- vaccinees$Y
weights_vaccine <- vaccinees$weights
X_vaccine <- vaccinees %>%
  select(-Y, -weights)

# ----------------------------------------------------------------------------------------------
# FIGURE 3, 4: do variable importance relative to baseline risk vars only
# ----------------------------------------------------------------------------------------------
risk_type <- "auc"
scale <- "logit"

# set up the full fits
full_fit_11_all <- sl_fits_varset_11_all
full_fit_10_tcells_fxab <- sl_fits_varset_10_tcells_fxab
full_fit_9_igg_iga_igg3_fxab <- sl_fits_varset_9_igg_iga_igg3_fxab
full_fit_8_igg_iga_igg3_tcells <- sl_fits_varset_8_igg_iga_igg3_tcells
full_fit_7_igg_iga_tcells <- sl_fits_varset_7_igg_iga_tcells
full_fit_6_igg_iga_igg3 <- sl_fits_varset_6_igg_iga_igg3
full_fit_5_fxab <- sl_fits_varset_5_fxab
full_fit_4_tcells <- sl_fits_varset_4_tcells
full_fit_3_igg3 <- sl_fits_varset_3_igg3
full_fit_2_igg_iga <- sl_fits_varset_2_igg_iga

# reduced fits
reduced_fit_none <- sl_fits_varset_1_baseline_exposure # for importance of all markers

# compute variable importance
vimp_all_markers <- get_cv_vim_precomputed(full_ests = avg_aucs_11_all,
                                           reduced_ests = avg_aucs_1_baseline_exposure,
                                           risk_type = risk_type,
                                           scale = scale)
vimp_tcells_fxab <- get_cv_vim_precomputed(full_ests = avg_aucs_10_tcells_fxab,
                                           reduced_ests = avg_aucs_1_baseline_exposure,
                                           risk_type = risk_type,
                                           scale = scale)
vimp_igg_iga_igg3_fxab <- get_cv_vim_precomputed(full_ests = avg_aucs_9_igg_iga_igg3_fxab,
                                                 reduced_ests = avg_aucs_1_baseline_exposure,
                                                 risk_type = risk_type,
                                                 scale = scale)
vimp_igg_iga_igg3_tcells <- get_cv_vim_precomputed(full_ests = avg_aucs_8_igg_iga_igg3_tcells,
                                                   reduced_ests = avg_aucs_1_baseline_exposure,
                                                   risk_type = risk_type,
                                                   scale = scale)
vimp_igg_iga_tcells <- get_cv_vim_precomputed(full_ests = avg_aucs_7_igg_iga_tcells,
                                              reduced_ests = avg_aucs_1_baseline_exposure,
                                              risk_type = risk_type,
                                              scale = scale)
vimp_igg_iga_igg3 <- get_cv_vim_precomputed(full_ests = avg_aucs_6_igg_iga_igg3,
                                            reduced_ests = avg_aucs_1_baseline_exposure,
                                            risk_type = risk_type,
                                            scale = scale)
vimp_fxab <- get_cv_vim_precomputed(full_ests = avg_aucs_5_fxab,
                                    reduced_ests = avg_aucs_1_baseline_exposure,
                                    risk_type = risk_type,
                                    scale = scale)
vimp_tcells <- get_cv_vim_precomputed(full_ests = avg_aucs_4_tcells,
                                      reduced_ests = avg_aucs_1_baseline_exposure,
                                      risk_type = risk_type,
                                      scale = scale)
vimp_igg3 <- get_cv_vim_precomputed(full_ests = avg_aucs_3_igg3,
                                    reduced_ests = avg_aucs_1_baseline_exposure,
                                    risk_type = risk_type,
                                    scale = scale)
vimp_igg_iga <- get_cv_vim_precomputed(full_ests = avg_aucs_2_igg_iga,
                                       reduced_ests = avg_aucs_1_baseline_exposure,
                                       risk_type = risk_type,
                                       scale = scale)
# combine together
vimp_tibble <- tibble(assay_grp = c("All markers",
                                    "T Cells + Fx Ab",
                                    "IgG + IgA + IgG3 + Fx Ab",
                                    "IgG + IgA + IgG3 + T Cells",
                                    "IgG + IgA + T Cells",
                                    "IgG + IgA + IgG3",
                                    "Fx Ab",
                                    "T Cells",
                                    "IgG3",
                                    "IgG + IgA"),
                      est = c(vimp_all_markers$est,
                              vimp_tcells_fxab$est,
                              vimp_igg_iga_igg3_fxab$est,
                              vimp_igg_iga_igg3_tcells$est,
                              vimp_igg_iga_tcells$est,
                              vimp_igg_iga_igg3$est,
                              vimp_fxab$est,
                              vimp_tcells$est,
                              vimp_igg3$est,
                              vimp_igg_iga$est),
                      cil = c(vimp_all_markers$ci_ll,
                              vimp_tcells_fxab$ci_ll,
                              vimp_igg_iga_igg3_fxab$ci_ll,
                              vimp_igg_iga_igg3_tcells$ci_ll,
                              vimp_igg_iga_tcells$ci_ll,
                              vimp_igg_iga_igg3$ci_ll,
                              vimp_fxab$ci_ll,
                              vimp_tcells$ci_ll,
                              vimp_igg3$ci_ll,
                              vimp_igg_iga$ci_ll),
                      ciu = c(vimp_all_markers$ci_ul,
                              vimp_tcells_fxab$ci_ul,
                              vimp_igg_iga_igg3_fxab$ci_ul,
                              vimp_igg_iga_igg3_tcells$ci_ul,
                              vimp_igg_iga_tcells$ci_ul,
                              vimp_igg_iga_igg3$ci_ul,
                              vimp_fxab$ci_ul,
                              vimp_tcells$ci_ul,
                              vimp_igg3$ci_ul,
                              vimp_igg_iga$ci_ul))
vimp_tibble <- tibble::add_column(vimp_tibble,
                                  immunoassay_set = get_immunoassay_set(vimp_tibble$assay_grp))
```

The results based on cross-validated AUC are presented in Figure \@ref(fig:vimp-plot-auc). Here, we see that using the group of all marker variables results in an estimated increase in cross-validated AUC of only `r round((vimp_tibble %>% filter(assay_grp == "All markers"))$est, 3)` over using the baseline risk variables only. Interestingly, the groups of IgG, IgA, IgG3, and T cell markers; IgG, IgA, and T cell markers; and T cell markers and those markers measured in functional antibody assays have estimated equivalent prediction performance. The most important group appears to be IgG3 markers, with an estimated increase in cross-validated AUC of approximately `r round((vimp_tibble %>% filter(assay_grp == "IgG3"))$est, 3)` compared to using baseline risk variables only. Again, these results must be interpreted with the large caveat that we have used a restricted set of learners in our Super Learner library to reduce computation time. A fuller set of learners is recommended for any publication-ready analysis.

```{r vimp-plot-auc, fig.cap = "Estimated variable importance (based on the difference in AUCs relative to a model with baseline exposure variables only) for each assay combination.", fig.height = 8, fig.width = 20, eval = FALSE}
title_font_size <- 26
main_font_size_forest <- 31
main_font_size_lab <- 9.3
y_title <- 0.945
point_size <- 5
lgnd_pos <- c(0.75, 0.8)
# forest plot of vimp, with labels for the groups
vimp_forest_plot <- vimp_tibble %>%
  ggplot(aes(x = est, y = factor(assay_grp,
                                 levels = assay_grp[order(est, decreasing = TRUE)],
                                 labels = assay_grp[order(est, decreasing = TRUE)]))) +
  geom_errorbarh(aes(xmin = cil, xmax = ciu, color = immunoassay_set), size = point_size/2) +
  geom_point(size = point_size) +
  scale_color_manual(values = cbbPalette[-2]) +
  ylab("Month 7 Marker Set") +
  labs(color = "Assay set") +
  xlab(paste0("Variable importance estimate: difference in CV-",
              ifelse(risk_type == "r_squared", expression(R^2), "AUC"))) +
  theme(legend.position = lgnd_pos,
        axis.text.y = element_text(size = main_font_size_forest),
        text = element_text(size = main_font_size_forest),
        axis.title = element_text(size = main_font_size_forest),
        axis.text.x = element_text(size = main_font_size_forest),
        axis.title.x = element_text(margin = ggplot2::margin(t = 20, r = 0,
                                                             b = 0, l = 0),
                                    size = main_font_size_forest),
        plot.margin=unit(c(1,0.5,0,0),"cm")) # top, right, bottom, left
vimp_forest_plot
```

# Conclusions

In this analysis, we developed a model that predicts HIV-1 infection in vaccinees from month 7 marker variables and baseline risk variables. This model employs nested cross-validation to combine a flexible library of individual learners into a prediction algorithm that admits desirable asymptotic properties: namely, that the resulting cross-validated estimator is asymptotically guaranteed to have the same risk as the oracle estimator.

Based on a variable importance analysis using the difference in cross-validated AUCs, we see that: (i) adding IgG and IgA variables only to baseline variables results in improved prediction performance; (ii) adding functional antibody variables and IgG3 variables to IgG and IgA variables and baseline variables results in improved prediction performance over adding IgG and IgA variables alone to baseline variables; (iii) adding T cell variables or functional antibody variables only results in the largest increase in prediction performance among all individual groups; and (iv) that combining T cell and antibody variables together results in a further incremental improvement over T cells alone, but only if all antibody classes are present.

The main limitation of this analysis is that, to save computation time in this vignette, we used a small library of candidate learning algorithms. The Appendix contains code that may be used to fully reproduce the analysis in @neidich2019. Additionally, we did not show here results based on cross-validated $R^2$: due to the small number of events, cross-validated $R^2$ appears to be a poor estimator both of prediction performance and of variable importance. This is in line with previous work suggesting that $R^2$ may not always be appropriate for rare binary endpoints. We suspect that with a larger number of events the behavior of the $R^2$ estimators, and the conclusions drawn from using cross-validated $R^2$ to define both prediction performance and variable importance, would be more in line with the conclusions drawn from using cross-validated AUC.

# Appendix

Code to reproduce the full Super Learning analysis is provided here. The original analysis of the HVTN 505 data [@neidich2019] used a previous version of the `vimp` package (specifically, `vimp` version 1.3.0); in this version of the package, hypothesis testing was not available, and the regressions based on the group of covariates of interest (e.g., IgG + IgA variables) and the group of remaining covariates (e.g., all variables besides IgG + IgA) were estimated on the same data. In the updated `vimp` version used here (version 2.1.4), it is possible to do hypothesis testing and the inverse weighting is properly handled. However, the hypothesis testing relies on the regressions being estimated on separate splits of the data; we do not do that here to harmonize this analysis with the original analysis.

```{r run-full-sl, eval = FALSE, code = readLines("code/run_sl.R")}
```

Code to reproduce the full variable importance analysis:
```{r run-assays, eval = FALSE, code = readLines("code/run_sl_assays.R")}
```

# References
