---
title: "Investigating HIV-1 correlates of protection in HVTN 505"
author: "Brian Williamson"
date: "`r Sys.Date()`"
output: html_document
references:
- id: williamson2017
  author:
  - family: Williamson
    given: Brian D
  - family: Gilbert
    given: Peter B
  - family: Simon
    given: Noah
  - family: Carone
    given: Marco
  publisher: University of Washington Department of Biostatistics Working Paper Series
  type: article-journal
  issued:
   year: 2017
  URL: 'http://biostats.bepress.com/uwbiostat/paper422/'
- id: fong2018
  author:
  - family: Fong
    given: Y
  - family: Shen
    given: X
  - family: Ashley
    given: VC
  - family: Deal
    given: A
  - family: et al.
  publisher: Journal of Infectious Diseases
  type: article-journal
  issued:
    year: 2018
  URL: 'https://doi.org/10.1093/infdis/jiy008'
- id: janes2017
  author:
    - family: Janes
      given: HE
    - family: Cohen
      given: KW
    - family: Frahm
      given: N
    - family: De Rosa
      given: SC
    - family: Sanchez
      given: G
    - family: et al.
  publisher: Journal of Infectious Diseases
  type: article-journal
  issued:
    year: 2017
  URL: 'https://doi.org/10.1093/infdis/jix086'
- id: hammer2013
  author:
    - family: Hammer
      given: SM
    - family: Sobieszczyk
      given: ME
    - family: Janes
      given: HE
    - family: Karuna
      given: ST
    - family: Mulligan
      given: MJ
    - family: et al.
  publisher: New England Journal of Medicine
  type: article-journal
  issued:
    year: 2013
  URL: 'https://doi.org/10.1056/NEJMoa1310566'
- id: doksum2008
  author: 
    - family: Doksum
      given: K
    - family: Tang
      given: S
    - family: Tsui
      given: KW
  publisher: Journal of the American Statistical Association
  type: article-journal
  issued:
    year: 2008
  URL: 'https://doi.org/10.1198/016214508000000878'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

We still do not have a broadly efficacious vaccine against HIV-1. [HVTN 505](https://clinicaltrials.gov/ct2/show/NCT00865566) was a randomized, placebo-controlled trial designed to assess the efficacy of a candidate vaccine regimen in adults. Using data from this trial, we aim to 

1. Build an *estimated optimal surrogate*, a model that best predicts HIV-1 infection risk from immune response marker variables measured at month 7 and a few baseline variables; and
2. Identify the sets of immune response markers that best predict infection and how these sets work together.

We use the Super Learner to address aim 1, and perform a variable importance analysis to address aim 2. Together, these aims constitute a correlates of risk (CoR) analysis using these data.

## Dataset

The month 7 immune markers are cross-classified by the following factors into interpretable sets:

1. Assay type: CD4 T Cell, CD8 T Cell, IgG, IgA, functional (phago, fcrR2a, fcrR3a, nAb tier 1)
2. Antigen: any vaccine-matched HIV peptide pool ("Any HIV"), protein-specific vaccine-matched peptide pools ("Any VRC ENV", "Any VRC GAG", "Any VRC NEF", and "Any VRC POL"), Empty Ad5 VRC, CMV, gp120, gp140, V1V2, V3, p24, gp41, C1, C4

A few of the month 7 immune markers had missing values. Single imputation was used to fill in these values. We ignore uncertainty in the imputations in this analysis (given the very small amount of missing data). 

We performed some data cleaning and a dimension reduction step prior to the statistical analysis. Within each interpretable variable set:

* include quantitative variables and binary "high" vs. "low" variables, defined by above vs. below the median of vaccine recipients. The median is calculated for the cohort of vaccine recipients at risk of HIV-1 infection at month 7; thus, inverse sampling probability weights are used in the calculations.
* each BAMA variable (IgG, IgG3, IgA) is baseline subtracted. For IgG3 the variables are log fold-rise in immune response, whereas IgG and IgA are the log of the difference (month 7 - month 0) on the original scale. In addition, for each BAMA variable month 7 readouts without baseline subtraction are included.
* For ICS variables (CD4, CD8 T cell), magnitude measures are: percent of cells expressing IL2, TNFa, CD154, and/or IFNg; percent of cells expressing IL2 and/or IFNg; percent of cells expressing IL2 and/or TNFa; and percent of cells expressing each of the individual cytokines (TNFa, CD154, IFNg, IL2, IL4).  All of the magnitudes are log10 net responses, i.e., background-subtracted and then log10-transformed.  Polyfunctionality as measured by the COMPASS polyfunctionality score (proportion of antigen-specific cell subsets detected, weighted by their degree of functionality, where antigen-specific cell subsets are those with a statistically-significant difference in the percent of cytokine-expressing cells in unstimulated vs. stimulated samples). The following cytokines are considered in calculating the polyfunctionality score: TNFa, CD154, IFNg, IL2, IL4, and Granzyme B; however cells expressing Granzyme B only are not counted as "functional".  Note functionality scores are not included because they are highly correlated and mostly redundant conceptually with polyfunctionality scores.  Both magnitude and polyfunctional score variables are included for study, as the correlations are not uniformly high; they range from ~0.5--0.8 across antigens and T cell subsets -- and may capture different aspects of T cell response.
* For ICS responses to vaccine-mismatched antigens (Empty Ad5 VRC and CMV antigens), measure responses using the percent of cells expressing IL2, TNFa, CD154, and/or IFNg.
* For variables with a positive response call (IgG, IgG3, IgA, R2a, R3a, phago, Tier 1 nAb) require $>$ 20% vaccine group positive response.  For all variables, require a significantly greater response in the vaccine group than the placebo group to include in the analysis (Wilcoxon rank sum test 2-sided p $<$ 0.01).  Note that no Tier 1 nAb variables are included because none met the $>$ 20% vaccine group response criterion.
* For all variables in an interpretable variable set (defined by assay and antigen) that are for vaccine-mismatched antigens, aggregate the variables into two scores to be kept for CoR analysis: PC1 and the maximal diversity weighted score (MDWS).  

The data are included in the R package HVTN505. Install the package from `HVTN505_2019-4-25.tar.gz` using the following code:

```{r}
# only run this line if the package isn't already installed
# install.packages("HVTN505_2019-4-25.tar.gz", type = "source", repos = NULL)
```

The object `dat.505` contains 189 rows, clinical covariates, and both continuous and dichotomized immune response biomarkers. The object `var.505` contains metadata on the individual immune response biomarkers. The object `score.505` contains metadata on the summary immune response biomarkers.    

## Correlates of Risk Analysis

All models adjust for the same baseline exposure covariates adjusted for by [@janes2017], except race (white, black, Hispanic) is excluded to help avoid sparsity issues: age (years old at enrollment), BMI at enrollment (quantitative value in kg/m$^2$), and baseline behavioral risk (a weighted average of two binary risk factors identified by [@hammer2013]). All analyses use the same empirical inverse probability sampling weights used by [@janes2017] and [@fong2018].  These participant weights are included in the data file (`wt` column in `dat.505` in the R HVTN505 package).

### Candidate Variable Sets

We consider 11 candidate variable sets in this analysis, defined by assay combination:

1. All markers;
2. IgG + IgA; 
3. IgG3; 
4. T cells (CD4 and CD8);
5. Functional antibodies (Fx Ab);
6. IgG + IgA and IgG3;
7. IgG + IgA and T cells;
8. IgG + IgA and IgG3 and T cells;
9. IgG + IgA and IgG3 and Fx Ab;
10. T cells and Fx Ab; and
11. No markers.

In all analyses, as we mentioned above, we adjust for three baseline variables: age, BMI, and behavioral risk.

### Super Learning Analysis

We use the implementation of the Super Learner provided in the `SuperLearner` R package. In a Super Learning task, cross-validation is used to determine the optimal convex combination of a set of candidate learners chosen to minimize a cross-validated risk. This process results in an estimated risk for each of the candidate learners, along with an estimated risk fo the traditional cross-validated selector and the optimal convex combination of the individual algorithms. This convex combination is called the Super Learner.

Specifying the set of candidate learners involves two steps: (1) specifying variable screens that reduce the number of variables passed to each algorithm, and (2) specifying a set of algorithms. The screens and algorithms are then combined, and each unique combination of screen and algorithm is applied to the regression problem.

Since we have only 25 events, we constructed aggressive variable screens that allowed a maximum of four marker variables into each candidate learner. In each case, the screen also included age, BMI, and baseline behavioral risk. The specific screens used are:

* dynamic range: exclude variables with 20th percentile equal to the 80th percentile
* dynamic range score: exclude all variables with standard deviation in the vaccinees divided by standard deviation in placebo recipients in the lower half of all participants
* lasso with fixed p-value threshold: exclude all variables for which a lasso (adjusting for age, BMI, and behavioral risk) results a p-value above a threshold. We considered thresholds 0.01, 0.05, and 0.1
* high correlation: exclude any pair of variables that has Spearman correlation greater than 0.9.

The specific Super Learner algorithms we considered were:

* generalized linear models;
* generalized linear models with pairwise interactions;
* forward stepwise regression with pairwise interactions;
* boosted decision stumps: boosted trees with maximum depth of one node; and
* the `earth` algorithm of [@doksum2008].

In each case, we used a logit link function to relate the predictor variables to the risk of HIV-1 infection.

These screens and algorithms are implemented in R using the following code:

```{r define-screens-and-algs}
## create SL screens, algorithm + screen combinations

## -------------------------------------------------------------------------------------
## SL screens; all models adjust for baseline covariates age, BMI at enrollment, baseline behavioral risk
## -------------------------------------------------------------------------------------
## screen based on logistic regression univariate p-value < level
rank_univariate_logistic_pval_plus_exposure <- function(Y, X, family, obsWeights, id, ...) {
    ## logistic regression of outcome on each variable
    listp <- apply(X, 2, function(x, Y, family) {
      summ <- coef(summary(glm(Y ~ x + X$age + X$BMI + X$bhvrisk, family = family, weights = obsWeights)))
        ifelse(dim(summ)[1] > 1, summ[2, 4], 1)
    }, Y = Y, family = family)
    ## rank the p-values; give age, BMI, bhvrisk the lowest rank (will always set to TRUE anyways)
    ranked_vars <- rank(listp, ties = "average")
    ranked_vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- 999
    return(ranked_vars)
}
## screen dynamic range: only keep variables with 20th percentile != 80th percentile
screen_dynamic_range_plus_exposure <- function(Y, X, family, obsWeights, id, nVar = 4, ...) {
  # set all vars to false
  vars <- rep(FALSE, ncol(X))
  
  # keep only those with dynamic range: 20th percentile != 80th percentile
  x_quantiles <- apply(X, 2, function(x) quantile(x, probs = c(0.2, 0.8)))
  vars <- apply(x_quantiles, 2, function(x) round(x[1], 4) != round(x[2], 4))
  # also keep the first three columns of X (correspond to age, BMI, bhvrisk)
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  # keep only a max of nVar immune markers; rank by univariate p-value in a model adjusting for age, BMI, bhvrisk
  X_initial_screen <- X %>%
    select(names(X)[vars], "age", "BMI", "bhvrisk")
  ranked_vars <- rank_univariate_logistic_pval_plus_exposure(Y, X_initial_screen, family, obsWeights, id)
  vars[vars][ranked_vars > nVar] <- FALSE
  
  # also keep the first three columns of X (correspond to age, BMI, bhvrisk)
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  return(vars)
}
## screen dynamic range score: only keep variables with sd(vacinees)/sd(placebo) > 75th percentile
## relies on having var.super loaded in the environment
screen_dynamic_range_score_plus_exposure <- function(Y, X, family, obsWeights, id, var_super = var.super, nVar = 4, ...) {
  # set all to false
  vars <- rep(FALSE, ncol(X))
  # need to apply with the correct label in place of X
  vars_sd_ratio <- ifelse(is.na(var_super$sd.ratio), TRUE, var_super$sd.ratio > quantile(var_super$sd.ratio, probs = c(0.5), na.rm = TRUE))
  vars <- names(X) %in% var_super$varname[vars_sd_ratio] | names(X) %in% paste0(var_super$varname[vars_sd_ratio], "_bin")
  # also keep the first three columns of X (correspond to age, BMI, bhvrisk)
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  # keep only a max of nVar immune markers; rank by univariate p-value in a model adjusting for age, BMI, bhvrisk
  X_initial_screen <- X %>%
    select(names(X)[vars], "age", "BMI", "bhvrisk")
  ranked_vars <- rank_univariate_logistic_pval_plus_exposure(Y, X_initial_screen, family, obsWeights, id)
  vars[vars][ranked_vars > nVar] <- FALSE
  # also keep the first three columns of X (correspond to age, BMI, bhvrisk)
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  return(vars)
}
## screen based on lasso 
screen_glmnet_plus_exposure <- function(Y, X, family, obsWeights, id, alpha = 1, minscreen = 2, nfolds = 10, nlambda = 100, nVar = 4, ...) {
  vars <- screen.glmnet(Y, X, family, obsWeights, id, alpha = 1, minscreen = 2, nfolds = 10, nlambda = 100, ...)
  # also keep the first three columns of X (correspond to age, BMI, bhvrisk)
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  # keep only a max of nVar immune markers; rank by univariate p-value in a model adjusting for age, BMI, bhvrisk
  X_initial_screen <- X %>%
    select(names(X)[vars], "age", "BMI", "bhvrisk")
  ranked_vars <- rank_univariate_logistic_pval_plus_exposure(Y, X_initial_screen, family, obsWeights, id)
  vars[vars][ranked_vars > nVar] <- FALSE
  # also keep the first three columns of X (correspond to age, BMI, bhvrisk)
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  return(vars)
}
## screen based on logistic regression univariate p-value < level
screen_univariate_logistic_pval_plus_exposure <- function(Y, X, family, obsWeights, id, minPvalue = 0.1, minscreen = 2, nVar = 4, ...) {
    ## logistic regression of outcome on each variable
    listp <- apply(X, 2, function(x, Y, family) {
      summ <- coef(summary(glm(Y ~ x + X$age + X$BMI + X$bhvrisk, family = family, weights = obsWeights)))
        ifelse(dim(summ)[1] > 1, summ[2, 4], 1)
    }, Y = Y, family = family)
    vars <- (listp <= minPvalue)
    # also keep the first three columns of X (correspond to age, BMI, bhvrisk)
    vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
    if (sum(vars) < minscreen) {
        warning("number of variables with p value less than minPvalue is less than minscreen")
        vars[rank(listp) <= minscreen] <- TRUE
    }
    # keep only a max of nVar immune markers; rank by univariate p-value in a model adjusting for age, BMI, bhvrisk
    X_initial_screen <- X %>%
      select(names(X)[vars], "age", "BMI", "bhvrisk")
    ranked_vars <- rank_univariate_logistic_pval_plus_exposure(Y, X_initial_screen, family, obsWeights, id)
    vars[vars][ranked_vars > nVar] <- FALSE
    vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
    return(vars)
}
screen_univariate_logistic_pval_plus_exposure_0.01 <- function(Y, X, family, obsWeights, id, minPvalue = 0.01, minscreen = 2, ...) {
  screen_univariate_logistic_pval_plus_exposure(Y, X, family, obsWeights, id, minPvalue, minscreen = 2, ...)
}
screen_univariate_logistic_pval_plus_exposure_0.05 <- function(Y, X, family, obsWeights, id, minPvalue = 0.05, minscreen = 2, ...) {
  screen_univariate_logistic_pval_plus_exposure(Y, X, family, obsWeights, id, minPvalue, minscreen = 2, ...)
}
screen_univariate_logistic_pval_plus_exposure_0.1 <- function(Y, X, family, obsWeights, id, minPvalue = 0.1, minscreen = 2, ...) {
  screen_univariate_logistic_pval_plus_exposure(Y, X, family, obsWeights, id, minPvalue, minscreen = 2, ...)
}
screen_highcor_plus_exposure <- function(Y, X, family, obsWeights, id, nVar = 4, ...) {
  # set all vars to FALSE
  vars <- rep(FALSE, ncol(X))
  # compute pairwise correlations between all marker vars
  cors <- cor(X, method = "spearman")
  diag(cors) <- NA
  cor_less_0.9 <- (cors <= 0.9)
  # screen out those with r > 0.9
  vars <- apply(cor_less_0.9, 1, function(x) all(x, na.rm = TRUE))
  # also keep the first three columns of X (correspond to age, BMI, bhvrisk)
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  # keep only a max of nVar immune markers; rank by univariate p-value in a model adjusting for age, BMI, bhvrisk
  X_initial_screen <- X %>%
    select(names(X)[vars], "age", "BMI", "bhvrisk")
  ranked_vars <- rank_univariate_logistic_pval_plus_exposure(Y, X_initial_screen, family, obsWeights, id)
  vars[vars][ranked_vars > nVar] <- FALSE
  ## make sure that age, BMI, bhvrisk are true
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  return(vars)
}

## screen to always include the various variable sets
screen_assay_plus_exposure <- function(Y, X, family, obsWeights, id, assays, nVar = 4, ...) {
  ## set all vars to be false
  vars <- rep(FALSE, ncol(X))
  ## set vars with assay in name to be true
  ## may be more than one
  for (i in 1:length(assays)) {
    vars[grepl(assays[i], names(X))] <- TRUE
  }
  # also keep the first three columns of X (correspond to age, BMI, bhvrisk)
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  # keep only a max of nVar immune markers; rank by univariate p-value in a model adjusting for age, BMI, bhvrisk
  X_initial_screen <- X %>%
    select(names(X)[vars], "age", "BMI", "bhvrisk")
  ranked_vars <- rank_univariate_logistic_pval_plus_exposure(Y, X_initial_screen, family, obsWeights, id)
  vars[vars][ranked_vars > nVar] <- FALSE
  ## set baseline exposure vars to true
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  return(vars)
}

## actual screens for antigen combos
## baseline_exposure is the base model
screen_baseline_exposure <- function(Y, X, family, obsWeights, id, ...) {
  ## set all vars to false
  vars <- rep(FALSE, ncol(X))
  ## set baseline exposure vars to true
  vars[names(X) %in% c("age", "BMI", "bhvrisk")] <- TRUE
  return(vars)
}
screen_igg_iga_plus_exposure <- function(Y, X, family, obsWeights, id, ...) {
  screen_assay_plus_exposure(Y, X, family, obsWeights, id, assays = c("IgG", "IgA"))
}
screen_tcells_plus_exposure <- function(Y, X, family, obsWeights, id, ...) {
  screen_assay_plus_exposure(Y, X, family, obsWeights, id, assays = c("CD4", "CD8"))
}
screen_fxab_plus_exposure <- function(Y, X, family, obsWeights, id, ...) {
  screen_assay_plus_exposure(Y, X, family, obsWeights, id, assays = c("IgG3", "phago", "fcrR2a", "fcrR3a"))
}
screen_igg_iga_tcells_plus_exposure <- function(Y, X, family, obsWeights, id, ...) {
  screen_assay_plus_exposure(Y, X,family,  obsWeights, id, assays = c("IgG", "IgA", "CD4", "CD8"))
}
screen_igg_iga_fxab_plus_exposure <- function(Y, X, family, obsWeights, id, ...) {
  screen_assay_plus_exposure(Y, X, family, obsWeights, id, assays = c("IgG", "IgA", "IgG3", "phago", "fcrR2a", "fcrR3a"))
}
screen_tcells_fxab_plus_exposure <- function(Y, X, family, obsWeights, id, ...) {
  screen_assay_plus_exposure(Y, X, family, obsWeights, id, assays = c("CD4", "CD8", "IgG3", "phago", "fcrR2a", "fcrR3a"))
}

screens_with_assay_groups <- c("screen_glmnet_plus_exposure", paste0("screen_univariate_logistic_pval_plus_exposure_", c(0.01, 0.05, 0.1)),
             "screen_dynamic_range_plus_exposure", "screen_dynamic_range_score_plus_exposure",
             "screen_baseline_exposure", paste0("screen_", c("igg_iga", "tcells", "fxab", "igg_iga_tcells",
                                                             "igg_iga_fxab", "tcells_fxab"),
                                                "_plus_exposure"),
             "screen_highcor_plus_exposure")
screens <- c("screen_glmnet_plus_exposure", paste0("screen_univariate_logistic_pval_plus_exposure_", c(0.01, 0.05, 0.1)),
                  "screen_dynamic_range_plus_exposure", "screen_dynamic_range_score_plus_exposure",
                  "screen_highcor_plus_exposure")
## -------------------------------------------------------------------------------------
## SL algorithms
## -------------------------------------------------------------------------------------

## --------------------------------------------------------------------------
## define wrappers that are less memory-intensive than the usual SL functions
## --------------------------------------------------------------------------
# skinny glm
SL.glm.skinny <- function(Y, X, newX, family, obsWeights, ...){
  SL.glm.fit <- SL.glm(Y = Y, X = X, newX = newX, family = family, obsWeights = obsWeights, ...)
  SL.glm.fit$fit$object$y <- NULL
  SL.glm.fit$fit$object$model <- NULL
  SL.glm.fit$fit$object$residuals <- NULL
  SL.glm.fit$fit$object$fitted.values <- NULL
  SL.glm.fit$fit$object$effects <- NULL
  SL.glm.fit$fit$object$qr$qr <- NULL
  SL.glm.fit$fit$object$linear.predictors <- NULL
  SL.glm.fit$fit$object$weights <- NULL
  SL.glm.fit$fit$object$prior.weights <- NULL
  SL.glm.fit$fit$object$data <- NULL
  SL.glm.fit$fit$object$family$variance <- NULL
  SL.glm.fit$fit$object$family$dev.resids <- NULL
  SL.glm.fit$fit$object$family$aic <- NULL
  SL.glm.fit$fit$object$family$validmu <- NULL
  SL.glm.fit$fit$object$family$simulate <- NULL
  attr(SL.glm.fit$fit$object$terms, ".Environment") <- NULL
  attr(SL.glm.fit$fit$object$formula, ".Environment") <- NULL
  return(SL.glm.fit)
}

## skinny glm with interactions
SL.glm.interaction.skinny <- function(Y, X, newX, family, obsWeights, ...){
  SL.glm.fit <- SL.glm.interaction(Y = Y, X = X, newX = newX, family = family, obsWeights = obsWeights, ...)
  SL.glm.fit$fit$object$y <- NULL
  SL.glm.fit$fit$object$model <- NULL
  SL.glm.fit$fit$object$residuals <- NULL
  SL.glm.fit$fit$object$fitted.values <- NULL
  SL.glm.fit$fit$object$effects <- NULL
  SL.glm.fit$fit$object$qr$qr <- NULL
  SL.glm.fit$fit$object$linear.predictors <- NULL
  SL.glm.fit$fit$object$weights <- NULL
  SL.glm.fit$fit$object$prior.weights <- NULL
  SL.glm.fit$fit$object$data <- NULL
  SL.glm.fit$fit$object$family$variance <- NULL
  SL.glm.fit$fit$object$family$dev.resids <- NULL
  SL.glm.fit$fit$object$family$aic <- NULL
  SL.glm.fit$fit$object$family$validmu <- NULL
  SL.glm.fit$fit$object$family$simulate <- NULL
  attr(SL.glm.fit$fit$object$terms, ".Environment") <- NULL
  attr(SL.glm.fit$fit$object$formula, ".Environment") <- NULL
  return(SL.glm.fit)
}

# skinny stepwise with interactions
SL.step.interaction.skinny <- function(Y, X, newX, family, obsWeights, ...){
  SL.step.interaction.fit <- SL.step.interaction(Y = Y, X = X, newX = newX, family = family, 
                                                 obsWeights = obsWeights, direction = "forward", ...)
  SL.step.interaction.fit$fit$object$y <- NULL
  SL.step.interaction.fit$fit$object$model <- NULL
  SL.step.interaction.fit$fit$object$residuals <- NULL
  SL.step.interaction.fit$fit$object$fitted.values <- NULL
  SL.step.interaction.fit$fit$object$effects <- NULL
  SL.step.interaction.fit$fit$object$qr$qr <- NULL
  SL.step.interaction.fit$fit$object$linear.predictors <- NULL
  SL.step.interaction.fit$fit$object$weights <- NULL
  SL.step.interaction.fit$fit$object$prior.weights <- NULL
  SL.step.interaction.fit$fit$object$data <- NULL
  SL.step.interaction.fit$fit$object$family$variance <- NULL
  SL.step.interaction.fit$fit$object$family$dev.resids <- NULL
  SL.step.interaction.fit$fit$object$family$aic <- NULL
  SL.step.interaction.fit$fit$object$family$validmu <- NULL
  SL.step.interaction.fit$fit$object$family$simulate <- NULL
  attr(SL.step.interaction.fit$fit$object$terms, ".Environment") <- NULL
  attr(SL.step.interaction.fit$fit$object$formula, ".Environment") <- NULL
  return(SL.step.interaction.fit)
}

# skinny stepwise (forward)
SL.step.skinny <- function(Y, X, newX, family, obsWeights, ...){
  SL.step.fit <- SL.step(Y = Y, X = X, newX = newX, family = family, obsWeights = obsWeights, direction = "forward", ...)
  SL.step.fit$fit$object$y <- NULL
  SL.step.fit$fit$object$model <- NULL
  SL.step.fit$fit$object$residuals <- NULL
  SL.step.fit$fit$object$fitted.values <- NULL
  SL.step.fit$fit$object$effects <- NULL
  SL.step.fit$fit$object$qr$qr <- NULL
  SL.step.fit$fit$object$linear.predictors <- NULL
  SL.step.fit$fit$object$weights <- NULL
  SL.step.fit$fit$object$prior.weights <- NULL
  SL.step.fit$fit$object$data <- NULL
  SL.step.fit$fit$object$family$variance <- NULL
  SL.step.fit$fit$object$family$dev.resids <- NULL
  SL.step.fit$fit$object$family$aic <- NULL
  SL.step.fit$fit$object$family$validmu <- NULL
  SL.step.fit$fit$object$family$simulate <- NULL
  attr(SL.step.fit$fit$object$terms, ".Environment") <- NULL
  attr(SL.step.fit$fit$object$formula, ".Environment") <- NULL
  return(SL.step.fit)
}

# boosted decision stumps
SL.stumpboost <- function(Y, X, newX, family, obsWeights, ...){
  fit <- SL.xgboost(Y = Y, X = X, newX = newX, family = family, obsWeights = obsWeights, 
                    max_depth = 1, # so it's only a stump
                    ...)
  return(fit)
}

# naive bayes wrapper
SL.naivebayes <- function(Y, X, newX, family, obsWeights, laplace = 0, ...){
  SuperLearner:::.SL.require("e1071")
  if(family$family == "gaussian"){
    stop("SL.naivebayes only works with binary outcomes")
  }else{
    nb <- naiveBayes(y = Y, x = X, laplace = laplace)
    pred <- predict(nb, newX, type = "raw")[,2]
    out <- list(fit = list(object = nb), pred = pred)
    class(out$fit) <- "SL.naivebayes"
    return(out)
  }
}

# predict method for naive bayes wrapper
predict.SL.naivebayes <- function(object, newdata, ...){
  pred <- predict(object$object, newdata = newdata, type = "raw")[,2]
  return(pred)
}

# methods <- c("SL.glm.skinny", "SL.glm.interaction.skinny", "SL.step.interaction.skinny",
             # "SL.naivebayes", "SL.stumpboost", "SL.glmnet", "SL.earth")
methods <- c("SL.glm.skinny", "SL.glm.interaction.skinny", "SL.step.interaction.skinny",
             "SL.stumpboost", "SL.glmnet", "SL.earth")




## -------------------------------------------------------------------------------------
## Add all alg/screen combinations to global environment, create SL library
## -------------------------------------------------------------------------------------

#' This function takes a super learner method wrapper and a super learner
#' screen wrapper and combines them into a single wrapper and makes that 
#' wrapper available in the specified environment. It also makes a predict
#' method available in the specified environment.
#' @param method A super learner method wrapper. See ?SuperLearner::listWrappers(what = "method").
#' @param screen A super learner method wrapper. See ?SuperLearner::listWrappers(what = "screen").
#' @param envir The environment to assign the functions to (default is global environment)
#' @param verbose Print a message with the function names confirming their assignment?
assign_combined_function <- function(method, screen, envir = .GlobalEnv,
                                     verbose = TRUE){
  fn <- eval(parse(text = 
          paste0("function(Y, X, newX, obsWeights, family, ...){ \n",
                    "screen_call <- ", screen, "(Y = Y, X = X, newX = newX, obsWeights = obsWeights, family = family, ...) \n",
                    "method_call <- ", method, "(Y = Y, X = X[,screen_call,drop=FALSE], newX = newX[,screen_call,drop = FALSE], obsWeights = obsWeights, family = family, ...) \n",
                    "pred <- method_call$pred \n",
                    "fit <- list(object = method_call$fit$object, which_vars = screen_call) \n",
                    "class(fit) <- paste0('", screen, "', '_', '", method, "') \n",
                    "out <- list(fit = fit, pred = pred) \n",
                    "return(out) \n",
                    "}")))
  fn_name <- paste0(screen,"_",method)
  assign(x = fn_name, value = fn, envir = envir)
  if(verbose){
    message(paste0("Function ", fn_name, " now available in requested environment."))
  }
  if (method == "SL.glmnet") {
      pred_fn <- eval(parse(text = 
              paste0("function(object, newdata, ...){ \n",
                        "screen_newdata <- newdata[,object$which_vars,drop = FALSE] \n",
                        "pred <- predict(object$object, type = 'response', newx = as.matrix(screen_newdata), s = 'lambda.min', ...) \n",
                        "return(pred) \n",
                     "}")))
    } else if (method == "SL.stumpboost") {
      pred_fn <- eval(parse(text = 
              paste0("function(object, newdata, ...){ \n",
                        "screen_newdata <- newdata[,object$which_vars,drop = FALSE] \n",
                        "screen_newdata_2 <- matrix(unlist(lapply(screen_newdata, as.numeric)), nrow=nrow(screen_newdata), ncol=ncol(screen_newdata)) \n",
                        "pred <- predict(object$object, newdata = screen_newdata_2, ...) \n",
                        "return(pred) \n",
                     "}")))
    } else if (method == "SL.naivebayes") {
      pred_fn <- eval(parse(text = 
              paste0("function(object, newdata, ...){ \n",
                        "screen_newdata <- newdata[,object$which_vars,drop = FALSE] \n",
                        'pred <- predict(object$object, newdata = screen_newdata, type = "raw", ...)[,2] \n',
                        "return(pred) \n",
                     "}")))
    } else if (method == "SL.randomForest") {
      pred_fn <- eval(parse(text = 
              paste0("function(object, newdata, ...){ \n",
              "screen_newdata <- newdata[,object$which_vars,drop = FALSE] \n",
              "if (object$object$type != 'classification') {
                                    pred <- predict(object$object, newdata = screen_newdata, type = 'response')
                                }else {
                                    pred <- predict(object$object, newdata = screen_newdata, type = 'vote')[, 
                                        2]
                                }
                                pred",
                     "}")))
    }else {
      pred_fn <- eval(parse(text = 
              paste0("function(object, newdata, ...){ \n",
                        "screen_newdata <- newdata[,object$which_vars,drop = FALSE] \n",
                        "pred <- predict(object$object, type = 'response', newdata = screen_newdata, ...) \n",
                        "return(pred) \n",
                     "}")))
    }
  
  pred_fn_name <- paste0("predict.",screen,"_",method)
  assign(x = pred_fn_name, value = pred_fn, envir = envir)
  if(verbose){
    message(paste0("Function ", pred_fn_name, " now available in requested environment."))
  }
}

## make a data frame of all method/screen combinations needed
screen_method_frame_with_assay_groups <- expand.grid(screen = screens_with_assay_groups, method = methods)
screen_method_frame <- expand.grid(screen = screens, method = methods)

## add to global environment
apply(screen_method_frame_with_assay_groups, 1, function(x) {assign_combined_function(screen = x[1], method = x[2], verbose = FALSE)})
apply(screen_method_frame, 1, function(x) {assign_combined_function(screen = x[1], method = x[2], verbose = FALSE)})

## create SL library; reference method is glm with baseline exposure vars
SL_library_with_assay_groups <- c(apply(screen_method_frame_with_assay_groups, 1, paste0, collapse = "_"))
SL_library <- c(apply(screen_method_frame, 1, paste0, collapse = "_"))
```

We used two layers of nested cross-validation in this analysis. An outer layer of five-fold cross-validation stratified so that an equal proportion of events fell within each fold was used to obtain cross-validated estimates of risk. An inner layer of leave-one-out cross-validation was used to obtain estimates of the regression functions within each fold. We used the cross-validated negative log likelihood to determine our optimal convex combination of learners. Since the results may depend on the random number seed used to generate the folds for the outer layer of five-fold cross-validation, we used ten random seeds, and for each seed ran the full nested cross-validation.

Our resulting proposed estimator for objective (1) above is the cross-validated Super Learner averaged over the ten random seeds, where each prediction is based on a leave-one-out cross-validated Super Learner when the particular observation was in the outer validation fold.


### Variable Importance

## Results


## Conclusions